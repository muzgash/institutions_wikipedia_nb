{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d094bd00-1254-4ab8-9139-cdaa5cbb2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from imageio import imread\n",
    "from urllib.parse import unquote\n",
    "import unidecode\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b121add3-ac0f-4189-8ac9-903e362b0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_names(url=\"\",name=\"\",lang=\"en\"):\n",
    "    '''\n",
    "    Find the different possible names of a wikipedia entity.\n",
    "    Right now it is only tested on organizations gotten from ror db\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The wikipedia url if is available\n",
    "    name : str\n",
    "        The name of keywords to do the search over wikipedia api\n",
    "    lang : str\n",
    "        The iso-639 lang code to fix the language endpooint of the search language\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        The response of the wikipedia requests with the langlinks of the prop params\n",
    "        \n",
    "    '''\n",
    "    if url:\n",
    "        subject = unquote(url.split(\"/\")[-1].replace(\"_\",\" \"))\n",
    "    elif name:\n",
    "        subject = name\n",
    "    else:\n",
    "        return {\"response\":[],\"names\":[]}\n",
    "    \n",
    "    base = 'https://'+lang+'.wikipedia.org/w/api.php'\n",
    "    #searching entire wikipedia\n",
    "    print(\"Searching \",subject)\n",
    "    params = {\n",
    "            'action':'query',\n",
    "            'format':'json',\n",
    "            'list':'search',\n",
    "            'srsearch':subject\n",
    "        }\n",
    " \n",
    "    data = requests.get(base, params=params).json()\n",
    "    #print(data)\n",
    "    entry=\"\"\n",
    "    pageid=\"\"\n",
    "    if not \"query\" in data.keys():\n",
    "        return None\n",
    "    for reg in data[\"query\"][\"search\"]: #searching among the results and checking twice with fuzzywuzzy\n",
    "        score=fuzz.ratio(reg[\"title\"].lower(),subject.lower())\n",
    "        if score>90:\n",
    "            entry=reg\n",
    "            pageid=int(reg[\"pageid\"])\n",
    "        elif score>50:\n",
    "            score=fuzz.partial_ratio(reg[\"title\"].lower(),subject.lower())\n",
    "            if score>95:\n",
    "                entry=reg\n",
    "                pageid=int(reg[\"pageid\"])\n",
    "            elif score>80:\n",
    "                score=fuzz.token_set_ratio(reg[\"title\"].lower(),subject.lower())\n",
    "                if score>98:\n",
    "                    entry=reg\n",
    "                    pageid=int(reg[\"pageid\"])\n",
    "        if entry!=\"\":\n",
    "            break\n",
    "\n",
    "    if pageid!=\"\": #if the page id is available\n",
    "        #retrieving the actual page's langlinks \n",
    "        params = {\n",
    "                'action': 'query',\n",
    "                'format': 'json',\n",
    "                'pageids': pageid,\n",
    "                'prop': 'langlinks',\n",
    "                'lllimit':500,\n",
    "                #'exintro': True,\n",
    "                #'explaintext': True,\n",
    "            }\n",
    "\n",
    "        response = requests.get(base, params=params)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf710eb-cc48-49f5-b91f-61e559cea875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_wikipedia_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Find the different possible names of a wikipedia entity.\n",
       "Right now it is only tested on organizations gotten from ror db\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "url : str\n",
       "    The wikipedia url if is available\n",
       "name : str\n",
       "    The name of keywords to do the search over wikipedia api\n",
       "lang : str\n",
       "    The iso-639 lang code to fix the language endpooint of the search language\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "data : dict\n",
       "    The response of the wikipedia requests with the langlinks of the prop params\n",
       "    \n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_3545795/3214475295.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_wikipedia_names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7587e4e8-4c38-4060-9f40-4f78371e30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching  universidad de antioquia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batchcomplete': '',\n",
       " 'query': {'pages': {'120427': {'pageid': 120427,\n",
       "    'ns': 0,\n",
       "    'title': 'Universidad de Antioquia',\n",
       "    'langlinks': [{'lang': 'ca', '*': \"Universitat d'Antioquia\"},\n",
       "     {'lang': 'ceb', '*': 'University of Antioquia'},\n",
       "     {'lang': 'de', '*': 'Universidad de Antioquia'},\n",
       "     {'lang': 'en', '*': 'University of Antioquia'},\n",
       "     {'lang': 'eo', '*': 'Universitato de Antjokio'},\n",
       "     {'lang': 'et', '*': 'Antioquia Ülikool'},\n",
       "     {'lang': 'fr', '*': \"Université d'Antioquia\"},\n",
       "     {'lang': 'gd', '*': 'Oilthigh Antioquia'},\n",
       "     {'lang': 'ja', '*': 'アンティオキア大学'},\n",
       "     {'lang': 'nl', '*': 'Universiteit van Antioquia'},\n",
       "     {'lang': 'pl', '*': 'Uniwersytet Antioquia'},\n",
       "     {'lang': 'sv', '*': 'Antioquias universitet'},\n",
       "     {'lang': 'tl', '*': 'Unibersidad ng Antioquia'},\n",
       "     {'lang': 'uz', '*': 'Antiokiya universiteti'}]}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wikipedia_names(name=\"universidad de antioquia\",lang=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9009ae3f-a45f-429f-bf23-aa38a38ee10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching  University of Rovira i Virgili\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batchcomplete': '',\n",
       " 'query': {'pages': {'106170': {'pageid': 106170,\n",
       "    'ns': 0,\n",
       "    'title': 'University of Rovira i Virgili',\n",
       "    'langlinks': [{'lang': 'ar', '*': 'جامعة روبيرا الأول بيرجيلي'},\n",
       "     {'lang': 'arz', '*': 'جامعة روبيرا الاول بيرجيلى'},\n",
       "     {'lang': 'be', '*': 'Універсітэт імя Антоніа Равіра-і-Вірджылі'},\n",
       "     {'lang': 'ca', '*': 'Universitat Rovira i Virgili'},\n",
       "     {'lang': 'el', '*': 'Πανεπιστήμιο Ροβίρα ι Μπιρζίλι'},\n",
       "     {'lang': 'es', '*': 'Universidad Rovira i Virgili'},\n",
       "     {'lang': 'eu', '*': 'Rovira i Virgili Unibertsitatea'},\n",
       "     {'lang': 'fr', '*': 'Université Rovira i Virgili'},\n",
       "     {'lang': 'gl', '*': 'Universidade Rovira i Virgili'},\n",
       "     {'lang': 'it', '*': 'Università Rovira i Virgili'},\n",
       "     {'lang': 'ja', '*': 'ルビーラ・イ・ビルジーリ大学'},\n",
       "     {'lang': 'pt', '*': 'Universidade Rovira i Virgili'},\n",
       "     {'lang': 'zh', '*': '罗维拉-威尔吉利大学'}]}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wikipedia_names(url=\"https://en.wikipedia.org/wiki/University_of_Rovira_i_Virgili\",lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7f328d7-4a2d-4615-9682-bf50a5b6a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logo_wikipedia(url=\"\",name=\"\",lang=\"en\"):\n",
    "    '''\n",
    "    Find and image of a wikipedia page.\n",
    "    Right now it is only tested for the logos of organizations gotten from ror db\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The wikipedia url if is available\n",
    "    name : str\n",
    "        The name of keywords to do the search over wikipedia api\n",
    "    lang : str\n",
    "        The iso-639 lang code to fix the language endpooint of the search language\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        The response of the wikipedia request\n",
    "        \n",
    "    '''\n",
    "    if url:\n",
    "        subject = unquote(url.split(\"/\")[-1].replace(\"_\",\" \"))\n",
    "    elif name:\n",
    "        subject = name\n",
    "    else:\n",
    "        return {\"response\":[],\"names\":[]}\n",
    "    \n",
    "    base = 'https://'+lang+'.wikipedia.org/w/api.php'\n",
    "    #searching entire wikipedia\n",
    "    print(\"Searching \",subject)\n",
    "    params = {\n",
    "            'action':'query',\n",
    "            'format':'json',\n",
    "            'list':'search',\n",
    "            'srsearch':subject\n",
    "        }\n",
    " \n",
    "    data = requests.get(base, params=params).json()\n",
    "    #print(data)\n",
    "    entry=\"\"\n",
    "    pageid=\"\"\n",
    "    if not \"query\" in data.keys():\n",
    "        return None\n",
    "    for reg in data[\"query\"][\"search\"]:\n",
    "        score=fuzz.ratio(reg[\"title\"].lower(),subject.lower())\n",
    "        if score>90:\n",
    "            entry=reg\n",
    "            pageid=int(reg[\"pageid\"])\n",
    "        elif score>50:\n",
    "            score=fuzz.partial_ratio(reg[\"title\"].lower(),subject.lower())\n",
    "            if score>95:\n",
    "                entry=reg\n",
    "                pageid=int(reg[\"pageid\"])\n",
    "            elif score>80:\n",
    "                score=fuzz.token_set_ratio(reg[\"title\"].lower(),subject.lower())\n",
    "                if score>98:\n",
    "                    entry=reg\n",
    "                    pageid=int(reg[\"pageid\"])\n",
    "        if entry!=\"\":\n",
    "            break\n",
    "\n",
    "    if pageid!=\"\":\n",
    "        #retrieveing the actual page    \n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'pageids': pageid,\n",
    "            'prop': 'images'\n",
    "        }\n",
    "\n",
    "        response = requests.get(base, params=params)\n",
    "        data = response.json()\n",
    "        try:\n",
    "            title=\"\"\n",
    "            for img in data[\"query\"][\"pages\"][str(pageid)][\"images\"]:\n",
    "                if \"commons\" in img[\"title\"].lower(): #avoid the wikipedia logo\n",
    "                    continue\n",
    "                for keyword in [\"flag\", \"escudo\", \"logo\", \"shield\", \"bandera\"]:\n",
    "                    if keyword in img[\"title\"].lower():\n",
    "                        title=img[\"title\"]\n",
    "                        break\n",
    "                if title != \"\":\n",
    "                    break\n",
    "            print(\"title: \",title)\n",
    "            params = {\n",
    "                'action': 'query',\n",
    "                'format': 'json',\n",
    "                'titles': title,\n",
    "                'prop': 'imageinfo',\n",
    "                'iiprop':\"url\"\n",
    "            }\n",
    "            response = requests.get(base, params=params)\n",
    "            data = response.json()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(\"@@@@\")\n",
    "            print(\"Function error: \", e)\n",
    "            print(data)\n",
    "            print(\"@@@@\")\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33e5a0f0-a0f6-4232-8906-ad866c772aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching  atletico nacional\n",
      "title:  File:Escudo Atlético Nacional.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'continue': {'iistart': '2015-06-08T02:52:40Z', 'continue': '||'},\n",
       " 'query': {'pages': {'-1': {'ns': 6,\n",
       "    'title': 'File:Escudo Atlético Nacional.png',\n",
       "    'missing': '',\n",
       "    'known': '',\n",
       "    'imagerepository': 'shared',\n",
       "    'imageinfo': [{'url': 'https://upload.wikimedia.org/wikipedia/commons/9/9a/Escudo_de_Atl%C3%A9tico_Nacional.png',\n",
       "      'descriptionurl': 'https://commons.wikimedia.org/wiki/File:Escudo_de_Atl%C3%A9tico_Nacional.png',\n",
       "      'descriptionshorturl': 'https://commons.wikimedia.org/w/index.php?curid=40813953'}]}}}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logo_wikipedia(name=\"atletico nacional\",lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc350745-2bcb-4684-bf5e-744cf6dd7872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching  Universidad de Antioquia\n",
      "title:  Archivo:Escudo-UdeA.svg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'continue': {'iistart': '2008-02-13T05:32:03Z', 'continue': '||'},\n",
       " 'query': {'pages': {'-1': {'ns': 6,\n",
       "    'title': 'Archivo:Escudo-UdeA.svg',\n",
       "    'missing': '',\n",
       "    'known': '',\n",
       "    'imagerepository': 'shared',\n",
       "    'imageinfo': [{'url': 'https://upload.wikimedia.org/wikipedia/commons/f/fb/Escudo-UdeA.svg',\n",
       "      'descriptionurl': 'https://commons.wikimedia.org/wiki/File:Escudo-UdeA.svg',\n",
       "      'descriptionshorturl': 'https://commons.wikimedia.org/w/index.php?curid=3547086'}]}}}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logo_wikipedia(url=\"https://es.wikipedia.org/wiki/Universidad_de_Antioquia\",lang=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09697e-02d3-4db4-93f6-4ebb572da248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
